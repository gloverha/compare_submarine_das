{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a68eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import netCDF4 as nc\n",
    "import oceanDAS as odas\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import date, datetime, timezone\n",
    "from scipy import signal\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "%cd -q '/Users/hglover/Library/CloudStorage/Box-Box/FiberExperiments/DAScomparison_paper/'\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "h, f_noise, clrs = odas.all_line_info()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79c4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cf(das,dasTime,press,presTime,t1,numvals):\n",
    "    frq, psd_strain = signal.welch(das[(dasTime>t1) & (dasTime<(t1+numvals))], fs=2, window='hann', nperseg=fs*60*5)\n",
    "    frqP, psd_press = signal.welch(press[(presTime>t1) & (presTime<(t1+numvals))], fs=2, window='hann', nperseg=fs*60*5)   \n",
    "    psd_press = np.interp(frq,frqP,psd_press)\n",
    "    strain_fac = psd_press/psd_strain\n",
    "    return frq, strain_fac\n",
    "\n",
    "def calc_waves(das,dasTime,press,presTime,test_time,numvals,strainFac,frq,depth,f_cutoff):\n",
    "    L = len(test_time)\n",
    "    Te_Das = np.empty([L])*np.nan\n",
    "    Hs_Das = np.empty([L])*np.nan\n",
    "    Te_Pre = np.empty([L])*np.nan\n",
    "    Hs_Pre = np.empty([L])*np.nan\n",
    "    for jj in range(L):\n",
    "        temp = das[(dasTime>test_time[jj]) & (dasTime<(test_time[jj]+numvals))]\n",
    "        _, Te_Das[jj], Hs_Das[jj] = odas.DAS_wave_conversion(temp,2,depth,strainFac,frq,f_cutoff)\n",
    "        temp = press[(presTime>test_time[jj]) & (presTime<(test_time[jj]+numvals))]\n",
    "        _, Te_Pre[jj], Hs_Pre[jj] = odas.pres_wave_conversion(temp,2,depth)\n",
    "    Te_Das[Te_Das>20] = 20\n",
    "\n",
    "    # calculate rmse for hs and te\n",
    "    rms_te = np.sqrt(np.mean((Te_Das-Te_Pre)**2))\n",
    "    rms_hs = np.sqrt(np.mean((Hs_Das-Hs_Pre)**2))\n",
    "    \n",
    "    return rms_te,rms_hs\n",
    "\n",
    "def calc_waves_hom(das,dasTime,test_time,numvals,strainFac,frq,depth,f_cutoff):\n",
    "    L = len(test_time)\n",
    "    Te_Das = np.empty([L])*np.nan\n",
    "    Hs_Das = np.empty([L])*np.nan\n",
    "    \n",
    "    for jj in range(L):\n",
    "        temp = das[(dasTime>test_time[jj]) & (dasTime<(test_time[jj]+numvals))]\n",
    "        _, Te_Das[jj], Hs_Das[jj] = odas.DAS_wave_conversion(temp,2,depth,strainFac,frq,f_cutoff)\n",
    "    Te_Das[Te_Das>20] = 20\n",
    "\n",
    "    return Te_Das, Hs_Das\n",
    "\n",
    "\n",
    "def calc_cf_hom(das,dasTime,sspec,sfreq,sdate,t1,numvals):\n",
    "    frq, psd_strain = signal.welch(das[(dasTime>t1) & (dasTime<(t1+numvals))], fs=2.5, window='hann', nperseg=2*60*5)\n",
    "    temp = sspec[(sdate>t1-1) & (sdate<t1+30),:].flatten()\n",
    "    psd_press = np.interp(frq,sfreq,temp)\n",
    "    strain_fac = psd_press/psd_strain\n",
    "    return frq, strain_fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duck\n",
    "pname = 'DuckNC_Glover/'\n",
    "\n",
    "# load pressure\n",
    "with np.load(pname+'FRF-ocean_waveTs_awac-11m_202111.npz') as data:\n",
    "    press = data['p']\n",
    "    presTime = data['t']\n",
    "\n",
    "# load strain\n",
    "f = h5py.File(pname + 'ChNo436_Nov2021fromdown.hdf5', 'r') \n",
    "dasTime = f['Acquisition']['RawDataTime'][:]\n",
    "das = f['Acquisition']['RawData'][:] # unit of E\n",
    "fs = 2 # this is downsampled data at 2Hz\n",
    "h = 11 # load approx water depth for channel location\n",
    "\n",
    "# set training data periods\n",
    "numvals = 60*60\n",
    "t1 = datetime(2021, 11, 11, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "t2 = datetime(2021, 11, 24, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "train_time = np.arange(t1,t2,numvals)\n",
    "L_train = len(train_time)\n",
    "# Calculate strain factor for each point in the interval\n",
    "frq, strain_fac = calc_cf(das,dasTime,press,presTime,t1,numvals)                                          \n",
    "for jj in range(1,L_train):\n",
    "    _, temp = calc_cf(das,dasTime,press,presTime,train_time[jj],numvals)\n",
    "    strain_fac = np.vstack([strain_fac,temp])\n",
    "\n",
    "sf_cum = strain_fac[0,:]\n",
    "for jj in range(1,L_train):\n",
    "    temp = np.nanmedian(strain_fac[:jj,:],axis=0)\n",
    "    sf_cum = np.vstack([sf_cum,temp])\n",
    "\n",
    "\n",
    "\n",
    "# now calculate for the testing period for each                                         \n",
    "t1 = datetime(2021, 11, 18, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "t2 = datetime(2021, 11, 20, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "test_time = np.arange(t1,t2,numvals)\n",
    "\n",
    "rms_te_duck = np.empty(L_train)*np.nan\n",
    "rms_hs_duck = np.empty(L_train)*np.nan\n",
    "\n",
    "for jj in range(L_train):\n",
    "    C = sf_cum[jj,:]\n",
    "    rms_te_duck[jj], rms_hs_duck[jj] = calc_waves(das,dasTime,press,presTime,test_time,numvals,C,frq,h,f_noise[0])\n",
    "\n",
    "rms_te_duck = np.sort(rms_te_duck)[::-1]\n",
    "rms_hs_duck = np.sort(rms_hs_duck)[::-1]\n",
    "days_duck = np.arange(0,L_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44369daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNO\n",
    "pname = 'KNO_Glover/'\n",
    "\n",
    "# load pressure\n",
    "with np.load(pname + 'rbr_pres_temp_all.npz') as data:\n",
    "    press = data['p'][:,5] #5 is nearest ch124, h=11.5 m\n",
    "    presTime = data['tvec']\n",
    "\n",
    "# load strain data\n",
    "with np.load(pname + 'filtstrain_F1_ch124.npz') as data:\n",
    "    das = data['e']\n",
    "    dasTime = data['t']\n",
    "fs = 2\n",
    "h = 11\n",
    "\n",
    "# set training data periods\n",
    "numvals = 60*60\n",
    "t1 = datetime(2023, 1, 14, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "t2 = datetime(2023, 1, 29, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "train_time = np.arange(t1,t2,numvals)\n",
    "L_train = len(train_time)\n",
    "# Calculate strain factor for each point in the interval\n",
    "frq, strain_fac = calc_cf(das,dasTime,press,presTime,t1,numvals)                                          \n",
    "for jj in range(1,L_train):\n",
    "    _, temp = calc_cf(das,dasTime,press,presTime,train_time[jj],numvals)\n",
    "    strain_fac = np.vstack([strain_fac,temp])\n",
    "\n",
    "sf_cum = strain_fac[0,:]\n",
    "for jj in range(1,L_train):\n",
    "    temp = np.nanmedian(strain_fac[:jj,:],axis=0)\n",
    "    sf_cum = np.vstack([sf_cum,temp])\n",
    "\n",
    "\n",
    "# now calculate for the testing period for each                                         \n",
    "t1 = datetime(2023, 1, 17, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "t2 = datetime(2023, 1, 20, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "test_time = np.arange(t1,t2,numvals)\n",
    "\n",
    "rms_te_kno = np.empty(L_train)*np.nan\n",
    "rms_hs_kno = np.empty(L_train)*np.nan\n",
    "\n",
    "for jj in range(L_train):\n",
    "    C = sf_cum[jj,:]\n",
    "    rms_te_kno[jj], rms_hs_kno[jj] = calc_waves(das,dasTime,press,presTime,test_time,numvals,C,frq,h,f_noise[1])\n",
    "\n",
    "rms_te_kno = np.sort(rms_te_kno)[::-1]\n",
    "rms_hs_kno = np.sort(rms_hs_kno)[::-1]\n",
    "days_kno = np.arange(0,L_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pname = 'HomerAK_Williams/'\n",
    "# load ground truth spectra:\n",
    "with h5py.File(pname+'NDBC-46108_spectra.h5','r') as fp:\n",
    "    sdate = fp['DATE'][2:]/1e9 # POSIX time stamp (s) (convert from ns to s)\n",
    "    sfreq = fp['FREQ'][:] # Hz\n",
    "    sspec = fp['SPEC'][2:,:] # m^2/Hz\n",
    "\n",
    "# load strain at all channels  then pull out channel 31\n",
    "fname = 'GCI_TERRA_2p5Hz_data.h5'\n",
    "onechn = False\n",
    "das,dasTime,chnl,depth,metadata = odas.loadHomer(pname,fname,onechn)\n",
    "das = das[~np.isnan(dasTime),31]\n",
    "dasTime = dasTime[~np.isnan(dasTime)][:]\n",
    "depth = depth[31]\n",
    "print(datetime.utcfromtimestamp(dasTime[0]))\n",
    "print(datetime.utcfromtimestamp(dasTime[-1]))\n",
    "\n",
    "# set training data periods\n",
    "numvals = 60*60\n",
    "t1 = datetime(2023, 6, 10, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "t2 = datetime(2023, 6, 25, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "train_time = np.arange(t1,t2,numvals)\n",
    "L_train = len(train_time)\n",
    "\n",
    "# Calculate strain factor for each point in the interval\n",
    "frq, strain_fac = calc_cf_hom(das,dasTime,sspec,sfreq,sdate,t1,numvals)                                          \n",
    "for jj in range(1,L_train):\n",
    "    _, temp = calc_cf_hom(das,dasTime,sspec,sfreq,sdate,train_time[jj],numvals)\n",
    "    strain_fac = np.vstack([strain_fac,temp])\n",
    "\n",
    "sf_cum = strain_fac[0,:]\n",
    "for jj in range(1,L_train):\n",
    "    temp = np.nanmedian(strain_fac[:jj,:],axis=0)\n",
    "    sf_cum = np.vstack([sf_cum,temp])\n",
    "\n",
    "\n",
    "\n",
    "# now calculate for the testing period for each                                         \n",
    "t1 = datetime(2023, 6, 25, 0, 0, 0,tzinfo=timezone.utc).timestamp()\n",
    "t2 = datetime(2023, 6, 27, 0, 20, 0,tzinfo=timezone.utc).timestamp()\n",
    "test_time = np.arange(t1,t2,numvals)\n",
    "\n",
    "\n",
    "# calculate wave stats from spectra for comparison:\n",
    "sspec = sspec[(sdate>=t1) & (sdate<=t2),:]\n",
    "sdate = sdate[(sdate>=t1) & (sdate<=t2)]\n",
    "L = len(sdate)\n",
    "Hs_Pre = np.zeros(L)\n",
    "Te_Pre = np.zeros(L)\n",
    "for jj in range(L):\n",
    "    ds_psd_corr = sspec[jj,(sfreq > 0.04) & (sfreq < 0.35)]\n",
    "    f_psd = sfreq[(sfreq > 0.04) & (sfreq < 0.35)]\n",
    "    fe = ((ds_psd_corr * f_psd) / ds_psd_corr.sum() ).sum() #(f*E)/E\n",
    "    Te_Pre[jj] = 1/fe\n",
    "    bandwidth = (f_psd[1::] - f_psd[0:-1]).mean()\n",
    "    Hs_Pre[jj] = 4*np.sqrt( ds_psd_corr.sum() * bandwidth ) \n",
    "\n",
    "\n",
    "rms_te = np.empty(L_train)*np.nan\n",
    "rms_hs = np.empty(L_train)*np.nan\n",
    "for jj in range(L_train):\n",
    "    C = sf_cum[jj,:]\n",
    "    Te_Das, Hs_Das = calc_waves_hom(das,dasTime,test_time,numvals,C,frq,44,f_noise[4])\n",
    "    # calculate rmse for hs and te\n",
    "    mask = np.isfinite(Te_Das) & np.isfinite(Te_Pre)\n",
    "    rms_te[jj] = np.sqrt(np.mean((Te_Das[mask]-Te_Pre[mask])**2))\n",
    "    mask = np.isfinite(Hs_Das) & np.isfinite(Hs_Pre)\n",
    "    rms_hs[jj] = np.sqrt(np.mean((Hs_Das[mask]-Hs_Pre[mask])**2))\n",
    "\n",
    "rms_te_hom = np.sort(rms_te)[::-1]\n",
    "rms_hs_hom = np.sort(rms_hs)[::-1]\n",
    "days_hom = np.arange(0,L_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff4512",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,figsize=(7,9))\n",
    "ax[0].plot(days_duck/24,rms_hs_duck,label='Duck, NC',c = 'gold',linewidth=2.5)\n",
    "ax[0].plot(days_kno/24,rms_hs_kno,label='Honolulu, HI',c = clrs[1],linewidth=2.5)\n",
    "ax[0].plot(days_hom/24,rms_hs_hom,label='Homer, AK',c = clrs[4],linewidth=2.5)\n",
    "# ax[0].set_xscale('log')\n",
    "# ax[0].set_xlabel('Hours of calibration data')\n",
    "ax[0].set_xlim([1/24,360/24])\n",
    "ax[0].set_ylim([0,0.24])\n",
    "ax[0].grid(which='major', axis='both')\n",
    "ax[0].set_ylabel('RMSE (m)')\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "ax[1].plot(days_duck/24,rms_te_duck,c = 'gold',linewidth=2.5)\n",
    "ax[1].plot(days_kno/24,rms_te_kno,c = clrs[1],linewidth=2.5)\n",
    "ax[1].plot(days_hom/24,rms_te_hom,c = clrs[4],linewidth=2.5)\n",
    "# ax[1].set_xscale('log')\n",
    "ax[1].grid(which='major', axis='both')\n",
    "ax[1].set_xlabel('Days of calibration data')\n",
    "ax[1].set_xlim([1/24,360/24])\n",
    "ax[1].set_ylim([0,1.4])\n",
    "ax[1].set_ylabel('RMSE (s)')\n",
    "\n",
    "\n",
    "ax[0].text(0.3,0.01, 'A) H$_s$')\n",
    "ax[1].text(0.3,0.1, 'B) T$_e$')\n",
    "\n",
    "fig.savefig('/Users/hglover/Library/CloudStorage/Box-Box/HannahGlover/writing/das_comparison/figs/F9_CalTime.pdf',dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
